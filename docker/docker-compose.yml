services:
  # ===========================================
  # CACHE
  # ===========================================
  redis:
    image: redis:7-alpine
    container_name: ai-server-redis
    command: redis-server --appendonly yes
    ports:
      - "${REDIS_PORT:-6380}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-server-network
    restart: unless-stopped

  # ===========================================
  # API (NestJS)
  # ===========================================
  api:
    build:
      context: ..
      dockerfile: apps/api/Dockerfile
    container_name: ai-server-api
    environment:
      NODE_ENV: ${NODE_ENV:-production}
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: redis://redis:6379
      JWT_SECRET: ${JWT_SECRET:-}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-7d}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY:-}
      # API always listens on 3001 internally
      API_PORT: 3001
      API_PORT_FALLBACK: "false"
      CORS_ORIGIN: ${CORS_ORIGIN:-http://localhost:3000}
      # AI Providers
      AI_PROVIDER: ${AI_PROVIDER:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      GEMINI_API_KEY: ${GEMINI_API_KEY:-}
      GEMINI_MODEL: ${GEMINI_MODEL:-gemini-1.5-flash}
      GROQ_API_KEY: ${GROQ_API_KEY:-}
      GROQ_MODEL: ${GROQ_MODEL:-llama-3.3-70b-versatile}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2}
    ports:
      # HOST_PORT:CONTAINER_PORT - Container always uses 3001
      - "${API_HOST_PORT:-3003}:3001"
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/api/health" ]
      interval: 30s
      timeout: 10s
      start_period: 30s
      retries: 3
    networks:
      - ai-server-network
    restart: unless-stopped

  # ===========================================
  # WEB (Next.js)
  # ===========================================
  web:
    build:
      context: ..
      dockerfile: apps/web/Dockerfile
      args:
        # Pass the API host port so WebSocket connections work correctly
        API_PORT: ${API_HOST_PORT:-3003}
    container_name: ai-server-web
    environment:
      NODE_ENV: ${NODE_ENV:-production}
      PORT: ${WEB_PORT:-3000}
      # Internal Docker network always uses port 3001 (API internal port)
      NEXT_PUBLIC_API_URL: http://api:3001
    ports:
      - "${WEB_PORT:-3000}:${WEB_PORT:-3000}"
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:3000/" ]
      interval: 30s
      timeout: 10s
      start_period: 30s
      retries: 3
    networks:
      - ai-server-network
    restart: unless-stopped

# ===========================================
# VOLUMES
# ===========================================
volumes:
  redis_data:
    driver: local
    name: ai-server-redis-data

# ===========================================
# NETWORKS
# ===========================================
networks:
  ai-server-network:
    driver: bridge
