# ============================================
# DATABASE CONFIGURATION
# ============================================
# Option 1: Remote Database (Recommended for production)
# Set DATABASE_URL directly for remote PostgreSQL (Supabase, Railway, etc.)
DATABASE_URL="postgresql://user:password@host:5432/database?schema=public"

# Option 2: Local Docker Database (for development)
# If using Docker, leave DATABASE_URL blank - it will be auto-generated
# from POSTGRES_* variables below

# JWT
JWT_SECRET="your-super-secret-jwt-key-change-in-production"
JWT_EXPIRES_IN="7d"

# Encryption (for SSH keys) - MUST be at least 32 characters
ENCRYPTION_KEY="your-32-character-encryption-key!"

# App
NODE_ENV="development"
API_PORT=3001
WEB_PORT=3000
CORS_ORIGIN="http://localhost:3000"

# ============================================
# AI PROVIDERS (configure at least one)
# ============================================

# Force specific provider (optional)
# Options: openai, gemini, groq, ollama
# If not set, uses first available in priority order
# AI_PROVIDER=gemini

# --------------------------------------------
# OpenAI (Paid)
# Get your key at: https://platform.openai.com/api-keys
# --------------------------------------------
OPENAI_API_KEY="sk-your-openai-api-key"
OPENAI_MODEL="gpt-4o-mini"

# --------------------------------------------
# Google Gemini (FREE TIER!)
# 60 requests/min, 1 million tokens/day
# Get your key at: https://aistudio.google.com/app/apikey
# --------------------------------------------
GEMINI_API_KEY="your-gemini-api-key"
GEMINI_MODEL="gemini-1.5-flash"

# --------------------------------------------
# Groq (FREE TIER!)
# 30 requests/min, 14,400 requests/day
# Get your key at: https://console.groq.com/keys
# --------------------------------------------
GROQ_API_KEY="your-groq-api-key"
GROQ_MODEL="llama-3.3-70b-versatile"

# --------------------------------------------
# Ollama (100% FREE - LOCAL!)
# Install: https://ollama.com
# Then run: ollama pull llama3.2
# --------------------------------------------
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3.2"

# ============================================
# DOCKER CONFIGURATION
# ============================================

# Database (for Docker)
POSTGRES_USER="aiserver_user"
POSTGRES_PASSWORD="aiserver_secret_2024"
POSTGRES_DB="aiserver_db"
# NOTE: Using non-default ports to avoid conflict with other projects (e.g., Grammarly)
POSTGRES_PORT=5433

# Redis (for Docker)
REDIS_PORT=6380

# ============================================
# PORT FALLBACK
# ============================================

# Enable automatic port fallback when port is in use
API_PORT_FALLBACK="true"
WEB_PORT_FALLBACK="true"

