# ============================================
# DATABASE CONFIGURATION
# ============================================
# Option 1: Remote Database (Recommended for production)
# Set DATABASE_URL directly for remote PostgreSQL (Supabase, Railway, etc.)
DATABASE_URL="postgresql://user:password@host:5432/database?schema=public"

# ============================================
# REDIS CONFIGURATION (Smart Docker Scaling)
# ============================================
# Option 1: Local Docker Redis (default)
# Just set the port, container will be started automatically
REDIS_PORT=6380

# Option 2: Remote Redis (Upstash, Redis Cloud, etc.)
# If REDIS_URL is set to a remote host, Docker Redis will NOT start
# REDIS_URL="redis://user:password@host:6379"

# JWT
JWT_SECRET="your-super-secret-jwt-key-change-in-production"
JWT_EXPIRES_IN="7d"

# Encryption (for SSH keys) - MUST be at least 32 characters
ENCRYPTION_KEY="your-32-character-encryption-key!"

# App
NODE_ENV="development"
API_PORT=3003
WEB_PORT=3002
CORS_ORIGIN="http://localhost:3002"

# ============================================
# AI PROVIDERS (configure at least one)
# ============================================

# Force specific provider (optional)
# Options: openai, gemini, groq, ollama
# If not set, uses first available in priority order
# AI_PROVIDER=gemini

# --------------------------------------------
# OpenAI (Paid)
# Get your key at: https://platform.openai.com/api-keys
# --------------------------------------------
OPENAI_API_KEY="sk-your-openai-api-key"
OPENAI_MODEL="gpt-4o-mini"

# --------------------------------------------
# Google Gemini (FREE TIER!)
# 60 requests/min, 1 million tokens/day
# Get your key at: https://aistudio.google.com/app/apikey
# --------------------------------------------
GEMINI_API_KEY="your-gemini-api-key"
GEMINI_MODEL="gemini-1.5-flash"

# --------------------------------------------
# Groq (FREE TIER!)
# 30 requests/min, 14,400 requests/day
# Get your key at: https://console.groq.com/keys
# --------------------------------------------
GROQ_API_KEY="your-groq-api-key"
GROQ_MODEL="llama-3.3-70b-versatile"

# --------------------------------------------
# Ollama (100% FREE - LOCAL!)
# Install: https://ollama.com
# Then run: ollama pull llama3.2
# --------------------------------------------
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3.2"

# ============================================
# PORT FALLBACK
# ============================================

# Enable automatic port fallback when port is in use
API_PORT_FALLBACK="true"
WEB_PORT_FALLBACK="true"

